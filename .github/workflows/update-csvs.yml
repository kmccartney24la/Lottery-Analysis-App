name: Update CSVs and upload to R2

on:
  schedule:
    # 04:45 UTC = 12:45 AM ET (daylight); safe window after GA's 11:34 PM ET draw
    - cron: '45 4 * * *'
  workflow_dispatch: {}

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest
    environment:
      name: r2-prod
    env:
      # Your inputs (as before)
      CF_ACCOUNT_ID: ${{ secrets.CF_ACCOUNT_ID || vars.CF_ACCOUNT_ID }}
      CF_API_TOKEN:  ${{ secrets.CF_API_TOKEN }}
      R2_BUCKET:     ${{ secrets.R2_BUCKET || vars.R2_BUCKET }}
      # Wrangler v4 reads these envs; we export them from CF_ in a step below
      CLOUDFLARE_ACCOUNT_ID: ""
      CLOUDFLARE_API_TOKEN:  ""

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Verify required secrets/vars are present
        run: |
          [ -z "$CF_ACCOUNT_ID" ] && echo "CF_ACCOUNT_ID is MISSING" && exit 1 || echo "CF_ACCOUNT_ID is set"
          [ -z "$CF_API_TOKEN" ]  && echo "CF_API_TOKEN is MISSING"  && exit 1 || echo "CF_API_TOKEN is set"
          [ -z "$R2_BUCKET" ]     && echo "R2_BUCKET is MISSING"     && exit 1 || echo "R2_BUCKET is set"

      - name: Use Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'

      - name: Cache scraper state (.cache)
        uses: actions/cache@v4
        with:
          path: .cache
          key: fantasy5-cache-${{ runner.os }}-${{ hashFiles('scripts/sources/fantasy5.mjs') }}
          restore-keys: |
            fantasy5-cache-${{ runner.os }}-

      - name: Install project dependencies
        run: npm ci

      - name: Install Playwright (Chromium only)
        run: npx playwright install --with-deps chromium

      - name: Install Wrangler v4 (pin)
        run: |
          npm i -D wrangler@4
          npx wrangler --version

      - name: Export Cloudflare env for Wrangler
        run: |
          echo "CLOUDFLARE_ACCOUNT_ID=$CF_ACCOUNT_ID" >> $GITHUB_ENV
          echo "CLOUDFLARE_API_TOKEN=$CF_API_TOKEN"   >> $GITHUB_ENV

      - name: Probe R2 and decide if we should seed full PB/MM history
        shell: bash
        run: |
          set -euo pipefail
          need_seed=0

   
          count_lines() {
            local key="$1"
            if npx --yes wrangler r2 object get "$R2_BUCKET/$key" --pipe --remote > /tmp/probe.csv 2>/dev/null; then
              wc -l < /tmp/probe.csv | tr -d ' '
            else
              echo 0
            fi
          }

          pb_lines=$(count_lines "multi/powerball.csv")
          mm_lines=$(count_lines "multi/megamillions.csv")

          echo "R2 probe: powerball.csv lines=$pb_lines ; megamillions.csv lines=$mm_lines"

    
          if [ "$pb_lines" -le 100 ] || [ "$mm_lines" -le 100 ]; then
           need_seed=1
          fi

          if [ "$need_seed" -eq 1 ]; then
           echo "LSP_SEED_FULL=1" >> "$GITHUB_ENV"
           echo "Seeding full history for PB/MM this run."
          else
            echo "No seed needed."
          fi

      - name: Run updater
        run: node scripts/update_csvs.mjs
        env:
          SOCRATA_APP_TOKEN: ${{ secrets.SOCRATA_APP_TOKEN }}
          SKIP_SOCRATA: '0'

      # =========== MERGE & GUARD ===========

      - name: Merge local CSV with existing R2 object (append-only)
        shell: bash
        run: |
          set -euo pipefail
          export LC_ALL=C LANG=C

          canon="draw_date,num1,num2,num3,num4,num5,special"

          function stripBOM(s){ return s && s.charCodeAt(0)===0xFEFF ? s.slice(1) : s; }
          function toYMD(s){
            if(!s) return '';
            const m = String(s).match(/^(\d{4}-\d{2}-\d{2})/);
            if (m) return m[1];
            const d = new Date(s);
            return isNaN(d) ? '' : d.toISOString().slice(0,10);
          }
          function int(x){ const n = parseInt(String(x).trim(),10); return Number.isFinite(n)?n:NaN; }
          function ints5(arr){ return arr.length===5 && arr.every(n=>Number.isInteger(n)); }

          function repair(inPath, outPath){
            if (!fs.existsSync(inPath) || fs.statSync(inPath).size === 0) {
              fs.writeFileSync(outPath, '', 'utf8'); return;
            }
            const text = fs.readFileSync(inPath, 'utf8').replace(/\r/g,'');
            const lines = text.split('\n').filter(l => l.length>0);
            if (lines.length === 0) { fs.writeFileSync(outPath, '', 'utf8'); return; }

            let header = stripBOM(lines[0]).trim().toLowerCase();
            const cols = header.split(',').map(s => s.trim());
            const idx = Object.fromEntries(cols.map((c,i)=>[c,i]));

            // Helper to emit canonical row in order
            const out = ['draw_date,num1,num2,num3,num4,num5,special'];

            // CASE 0: Already canonical — just pass through.
            if (header === 'draw_date,num1,num2,num3,num4,num5,special') {
              fs.writeFileSync(outPath, lines.join('\n')+'\n', 'utf8'); return;
            }

            // CASE 1: legacy Socrata: draw_date + winning_numbers + optional special name (mega_ball|cash_ball|powerball)
            if ('draw_date' in idx && 'winning_numbers' in idx) {
              const sname = ['special','mega_ball','cash_ball','powerball'].find(k=>k in idx);
              for (let i=1;i<lines.length;i++){
                const parts = lines[i].split(',');
                const date = toYMD(parts[idx['draw_date']]);
                const wn = String(parts[idx['winning_numbers']]||'');
                const nums = (wn.match(/\d+/g)||[]).map(Number);
                const whites = nums.slice(0,5);
                let special = '';
                if (sname && sname !== 'special') {
                  const sv = int(parts[idx[sname]]);
                  special = Number.isFinite(sv) ? String(sv) : '';
                } else if (nums.length >= 6) {
                  special = String(nums[5]);
                }
                if (date && ints5(whites)) out.push([date,...whites,special].join(','));
              }
              fs.writeFileSync(outPath, out.join('\n')+'\n', 'utf8'); return;
            }

            // CASE 2: column-based numeric names — accept num1..num5 OR m1..m5; special can be special|mega_ball|cash_ball|powerball
            const baseDate = ('draw_date' in idx) ? idx['draw_date'] : null;
            const choose = (...names)=> names.find(n => n in idx);
            const n1 = choose('num1','m1','n1');
            const n2 = choose('num2','m2','n2');
            const n3 = choose('num3','m3','n3');
            const n4 = choose('num4','m4','n4');
            const n5 = choose('num5','m5','n5');
            const sCol = choose('special','mega_ball','cash_ball','powerball');

            // Allow extra columns like 'game', 'special_name' — we just ignore them.
            const numericColsPresent = [n1,n2,n3,n4,n5].every(v => Number.isInteger(v));
            if (baseDate != null && numericColsPresent && sCol != null) {
              for (let i=1;i<lines.length;i++){
                const parts = lines[i].split(',');
                const date = toYMD(parts[baseDate]);
                const whites = [parts[n1],parts[n2],parts[n3],parts[n4],parts[n5]].map(int);
                const specialV = int(parts[sCol]);
                if (date && ints5(whites)) {
                  out.push([date, whites[0], whites[1], whites[2], whites[3], whites[4], Number.isFinite(specialV)?specialV:''].join(','));
                }
              }
              fs.writeFileSync(outPath, out.join('\n')+'\n', 'utf8'); return;
            }

            console.error('Unrecognized header layout:', header);
            process.exit(2);
          }

          const [,,inPath, outPath] = process.argv;
          repair(inPath, outPath);
          NODE
          }

          merge_csv() {
            local rel="$1"              # e.g. ga/cash4life.csv or multi/powerball.csv
            local local_file="public/data/$rel"

            sed -i 's/\r$//' "$local_file" 2>/dev/null || true

            local tmpdir r2_file r2_fixed local_fixed merged
            tmpdir="$(mktemp -d)"
            r2_file="$tmpdir/r2.csv"
            r2_fixed="$tmpdir/r2.fixed.csv"
            local_fixed="$tmpdir/local.fixed.csv"
            merged="$tmpdir/merged.csv"

            if npx --yes wrangler r2 object get "$R2_BUCKET/$rel" --pipe --remote > "$r2_file" 2>/dev/null; then
              echo "Fetched existing $rel from R2"
            else
              echo "No existing $rel in R2; starting fresh"
              : > "$r2_file"
            fi

            make_repair_js

            # Normalize R2 and local to canonical header
            npx tsx scripts/repair-lotto-csv.ts "$r2_file" "$r2_fixed"
            npx tsx scripts/repair-lotto-csv.ts "$local_file" "$local_fixed"

            # If local is empty (no new rows), just keep R2
            if [ ! -s "$local_fixed" ] || [ "$(tail -n +2 "$local_fixed" | sed '/^[[:space:]]*$/d' | wc -l)" -eq 0 ]; then
              echo "No new local rows for $rel; keeping R2 version."
              cp "$r2_fixed" "$local_file"
              return 0
            fi

            # Final sanity: headers must be canonical now
            head -n1 "$r2_fixed" | tr -d '\r' | grep -qx "$canon" || { echo "R2 header not canonical after repair"; exit 1; }
            head -n1 "$local_fixed" | tr -d '\r' | grep -qx "$canon" || { echo "Local header not canonical after repair"; exit 1; }

            # Track previous row count for anti-truncation
            prev_rows=$(tail -n +2 "$r2_fixed" | sed '/^[[:space:]]*$/d' | wc -l || echo 0)

            # Merge append-only, unique by draw_date, sorted by date
            {
              echo "$canon"
              (tail -n +2 "$r2_fixed"; tail -n +2 "$local_fixed") \
                | sed '/^[[:space:]]*$/d' \
                | awk -F, '!seen[$1]++' \
                | sort
            } > "$merged"

            merged_rows=$(tail -n +2 "$merged" | sed '/^[[:space:]]*$/d' | wc -l || echo 0)
            if [ "$merged_rows" -lt "$prev_rows" ]; then
              echo "ERROR: Anti-truncation triggered for $rel (merged $merged_rows < previous $prev_rows)."
              cp "$r2_fixed" "$local_file"
            else
              mv "$merged" "$local_file"
            fi

            echo "Post-merge $rel rows: prev=$prev_rows → now=$merged_rows"
            npx wrangler r2 object put "$R2_BUCKET/$rel" --file="$local_file" --content-type=text/csv --cache-control=public,max-age=3600,must-revalidate --remote
            echo "Uploaded $rel"
          }

          # Apply to the game you seeded; keeping others is fine too.
          merge_csv multi/powerball.csv
          merge_csv multi/megamillions.csv
          merge_csv ga/cash4life.csv
          merge_csv ga/fantasy5.csv


      - name: Show local CSVs (after merge, before upload)
        shell: bash
        run: |
          set -euo pipefail
          for f in \
            public/data/ga/fantasy5.csv \
            public/data/ga/cash4life.csv \
            public/data/multi/powerball.csv \
            public/data/multi/megamillions.csv
          do
            echo "---- $f ----"
            wc -l "$f" || true
            sed -n '1,5p' "$f" || true
            echo
          done

      # =========== UPLOADS via Wrangler v4 ===========

      - name: Upload merged CSVs to R2
        shell: bash
        run: |
          set -euo pipefail
          npx wrangler --version
          # Upload with cache headers
          npx wrangler r2 object put "$R2_BUCKET/ga/fantasy5.csv"       --file=public/data/ga/fantasy5.csv       --content-type=text/csv --cache-control=public,max-age=3600,must-revalidate --remote
          npx wrangler r2 object put "$R2_BUCKET/ga/cash4life.csv"      --file=public/data/ga/cash4life.csv      --content-type=text/csv --cache-control=public,max-age=3600,must-revalidate --remote
          npx wrangler r2 object put "$R2_BUCKET/multi/powerball.csv"   --file=public/data/multi/powerball.csv   --content-type=text/csv --cache-control=public,max-age=3600,must-revalidate --remote
          npx wrangler r2 object put "$R2_BUCKET/multi/megamillions.csv" --file=public/data/multi/megamillions.csv --content-type=text/csv --cache-control=public,max-age=3600,must-revalidate --remote

      - name: List R2 keys (debug)
        shell: bash
        run: |
          set -euo pipefail
          echo "Using bucket: $R2_BUCKET"
          echo "Objects under ga/:"
          npx wrangler r2 object list "$R2_BUCKET" --prefix ga/ --remote || true
          echo "Objects under multi/:"
          npx wrangler r2 object list "$R2_BUCKET" --prefix multi/ --remote || true


      - name: Verify R2 objects (self-heal if missing)
        shell: bash
        run: |
          set -euo pipefail

          verify_or_put () {
            local rel="$1"                      # e.g. ga/fantasy5.csv
            local local_file="public/data/$rel"

            # local must exist
            test -s "$local_file" || { echo "ERROR: local $rel missing or empty"; exit 1; }

            # try fetch; if missing, upload then fetch
            if ! npx wrangler r2 object get "$R2_BUCKET/$rel" --pipe --remote | tee /tmp/verify.csv >/dev/null; then
              echo "$rel not found in R2; uploading and retrying…"
              npx wrangler r2 object put "$R2_BUCKET/$rel" \
                --file="$local_file" \
                --content-type=text/csv \
                --cache-control=public,max-age=3600,must-revalidate \
                --remote
              npx wrangler r2 object get "$R2_BUCKET/$rel" --pipe --remote | tee /tmp/verify.csv >/dev/null
            fi

            local local_lines remote_lines
            local_lines=$(wc -l < "$local_file")
            remote_lines=$(wc -l < /tmp/verify.csv)
            echo "$rel lines: local=$local_lines remote=$remote_lines"

            test "$remote_lines" -ge "$local_lines" || { echo "ERROR: remote has fewer lines than local for $rel"; exit 1; }
          }

          verify_or_put ga/fantasy5.csv
          verify_or_put ga/cash4life.csv
          verify_or_put multi/powerball.csv
          verify_or_put multi/megamillions.csv


      - name: Post-upload sanity (counts from R2)
        shell: bash
        run: |
          set -euo pipefail
          check() {
            local key="$1"
            local tmp
            tmp="$(mktemp)"
            npx wrangler r2 object get "$R2_BUCKET/$key" --pipe > "$tmp"
            echo "R2: $key -> total lines: $(wc -l < "$tmp")"
            echo "Head:"
            sed -n '1,5p' "$tmp"
            echo
          }
          check ga/fantasy5.csv
          check ga/cash4life.csv
          check multi/powerball.csv
          check multi/megamillions.csv

      # -------- Commit at the end (CSV-only, safe) --------
      - name: Commit CSV changes only (safe)
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git restore --worktree --staged package.json package-lock.json 2>/dev/null || true
          git add public/data/ga public/data/multi

          if git diff --cached --quiet; then
            echo "No CSV changes to commit."
            exit 0
          fi

          echo "Changes to commit:"
          git diff --cached --name-status

          git commit -m "chore: update CSVs"
          git push
