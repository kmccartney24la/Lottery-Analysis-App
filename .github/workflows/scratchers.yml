name: Update GA Scratchers

on:
  schedule:
    # 09:30 America/New_York ~= 13:30 UTC during DST (cron uses UTC)
    - cron: '30 13 * * *'
  workflow_dispatch:

permissions:
  contents: read

jobs:
  scrape-and-upload:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    concurrency:
      group: ga-scratchers
      cancel-in-progress: true

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install deps
        run: npm ci --prefer-offline

      # (Optional) speed up Playwright by caching browser binaries
      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ms-playwright-${{ runner.os }}-chromium
          restore-keys: |
            ms-playwright-${{ runner.os }}-

      - name: Install Playwright (Chromium)
        run: npx playwright install --with-deps chromium

      - name: Fetch GA scratchers (build latest + merge)
        run: npx --yes tsx scripts/scratchers/fetch_ga_scratchers.ts

      - name: Verify required secrets
        run: |
          test -n "${{ secrets.CLOUDFLARE_ACCOUNT_ID }}" || { echo "❌ Missing CLOUDFLARE_ACCOUNT_ID secret"; exit 1; }
          test -n "${{ secrets.CLOUDFLARE_API_TOKEN }}"  || { echo "❌ Missing CLOUDFLARE_API_TOKEN secret";  exit 1; }
          test -n "${{ secrets.R2_BUCKET }}"            || { echo "❌ Missing R2_BUCKET secret";            exit 1; }

      # Use pinned Wrangler v4 via npx (no global install)
      - name: Upload to R2
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN:  ${{ secrets.CLOUDFLARE_API_TOKEN }}
          R2_BUCKET:             ${{ secrets.R2_BUCKET }}   # e.g. "my-bucket"
          R2_PREFIX:             ga/scratchers              # no leading slash
        run: |
          npx -y wrangler@4 r2 object put "$R2_BUCKET/$R2_PREFIX/index.latest.json" \
            --file public/data/ga_scratchers/index.latest.json --content-type application/json
          npx -y wrangler@4 r2 object put "$R2_BUCKET/$R2_PREFIX/index.json" \
            --file public/data/ga_scratchers/index.json --content-type application/json

      # Always publish artifacts for debugging (even if scraping or R2 upload failed)
      - name: Upload snapshot + debug artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ga-scratchers-artifacts
          path: |
            public/data/ga_scratchers/index.latest.json
            public/data/ga_scratchers/index.json
            public/data/ga_scratchers/_debug_top_prizes.png
            public/data/ga_scratchers/_debug_top_prizes.html
          if-no-files-found: warn
          retention-days: 7
